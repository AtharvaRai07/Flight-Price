{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4eebc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "916436ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>car_name</th>\n",
       "      <th>brand</th>\n",
       "      <th>model</th>\n",
       "      <th>vehicle_age</th>\n",
       "      <th>km_driven</th>\n",
       "      <th>seller_type</th>\n",
       "      <th>fuel_type</th>\n",
       "      <th>transmission_type</th>\n",
       "      <th>mileage</th>\n",
       "      <th>engine</th>\n",
       "      <th>max_power</th>\n",
       "      <th>seats</th>\n",
       "      <th>selling_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Maruti Alto</td>\n",
       "      <td>Maruti</td>\n",
       "      <td>Alto</td>\n",
       "      <td>9</td>\n",
       "      <td>120000</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Manual</td>\n",
       "      <td>19.70</td>\n",
       "      <td>796</td>\n",
       "      <td>46.30</td>\n",
       "      <td>5</td>\n",
       "      <td>120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hyundai Grand</td>\n",
       "      <td>Hyundai</td>\n",
       "      <td>Grand</td>\n",
       "      <td>5</td>\n",
       "      <td>20000</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Manual</td>\n",
       "      <td>18.90</td>\n",
       "      <td>1197</td>\n",
       "      <td>82.00</td>\n",
       "      <td>5</td>\n",
       "      <td>550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hyundai i20</td>\n",
       "      <td>Hyundai</td>\n",
       "      <td>i20</td>\n",
       "      <td>11</td>\n",
       "      <td>60000</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Manual</td>\n",
       "      <td>17.00</td>\n",
       "      <td>1197</td>\n",
       "      <td>80.00</td>\n",
       "      <td>5</td>\n",
       "      <td>215000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Maruti Alto</td>\n",
       "      <td>Maruti</td>\n",
       "      <td>Alto</td>\n",
       "      <td>9</td>\n",
       "      <td>37000</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Manual</td>\n",
       "      <td>20.92</td>\n",
       "      <td>998</td>\n",
       "      <td>67.10</td>\n",
       "      <td>5</td>\n",
       "      <td>226000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ford Ecosport</td>\n",
       "      <td>Ford</td>\n",
       "      <td>Ecosport</td>\n",
       "      <td>6</td>\n",
       "      <td>30000</td>\n",
       "      <td>Dealer</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Manual</td>\n",
       "      <td>22.77</td>\n",
       "      <td>1498</td>\n",
       "      <td>98.59</td>\n",
       "      <td>5</td>\n",
       "      <td>570000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        car_name    brand     model  vehicle_age  km_driven seller_type  \\\n",
       "0    Maruti Alto   Maruti      Alto            9     120000  Individual   \n",
       "1  Hyundai Grand  Hyundai     Grand            5      20000  Individual   \n",
       "2    Hyundai i20  Hyundai       i20           11      60000  Individual   \n",
       "3    Maruti Alto   Maruti      Alto            9      37000  Individual   \n",
       "4  Ford Ecosport     Ford  Ecosport            6      30000      Dealer   \n",
       "\n",
       "  fuel_type transmission_type  mileage  engine  max_power  seats  \\\n",
       "0    Petrol            Manual    19.70     796      46.30      5   \n",
       "1    Petrol            Manual    18.90    1197      82.00      5   \n",
       "2    Petrol            Manual    17.00    1197      80.00      5   \n",
       "3    Petrol            Manual    20.92     998      67.10      5   \n",
       "4    Diesel            Manual    22.77    1498      98.59      5   \n",
       "\n",
       "   selling_price  \n",
       "0         120000  \n",
       "1         550000  \n",
       "2         215000  \n",
       "3         226000  \n",
       "4         570000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('cardekho_imputated.csv',index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913eea79",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d7e11c",
   "metadata": {},
   "source": [
    "#### Handling Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "864c47b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "car_name             0\n",
       "brand                0\n",
       "model                0\n",
       "vehicle_age          0\n",
       "km_driven            0\n",
       "seller_type          0\n",
       "fuel_type            0\n",
       "transmission_type    0\n",
       "mileage              0\n",
       "engine               0\n",
       "max_power            0\n",
       "seats                0\n",
       "selling_price        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ba122b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['car_name','brand'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63630089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>vehicle_age</th>\n",
       "      <th>km_driven</th>\n",
       "      <th>seller_type</th>\n",
       "      <th>fuel_type</th>\n",
       "      <th>transmission_type</th>\n",
       "      <th>mileage</th>\n",
       "      <th>engine</th>\n",
       "      <th>max_power</th>\n",
       "      <th>seats</th>\n",
       "      <th>selling_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alto</td>\n",
       "      <td>9</td>\n",
       "      <td>120000</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Manual</td>\n",
       "      <td>19.70</td>\n",
       "      <td>796</td>\n",
       "      <td>46.30</td>\n",
       "      <td>5</td>\n",
       "      <td>120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Grand</td>\n",
       "      <td>5</td>\n",
       "      <td>20000</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Manual</td>\n",
       "      <td>18.90</td>\n",
       "      <td>1197</td>\n",
       "      <td>82.00</td>\n",
       "      <td>5</td>\n",
       "      <td>550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i20</td>\n",
       "      <td>11</td>\n",
       "      <td>60000</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Manual</td>\n",
       "      <td>17.00</td>\n",
       "      <td>1197</td>\n",
       "      <td>80.00</td>\n",
       "      <td>5</td>\n",
       "      <td>215000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alto</td>\n",
       "      <td>9</td>\n",
       "      <td>37000</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Manual</td>\n",
       "      <td>20.92</td>\n",
       "      <td>998</td>\n",
       "      <td>67.10</td>\n",
       "      <td>5</td>\n",
       "      <td>226000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ecosport</td>\n",
       "      <td>6</td>\n",
       "      <td>30000</td>\n",
       "      <td>Dealer</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Manual</td>\n",
       "      <td>22.77</td>\n",
       "      <td>1498</td>\n",
       "      <td>98.59</td>\n",
       "      <td>5</td>\n",
       "      <td>570000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model  vehicle_age  km_driven seller_type fuel_type transmission_type  \\\n",
       "0      Alto            9     120000  Individual    Petrol            Manual   \n",
       "1     Grand            5      20000  Individual    Petrol            Manual   \n",
       "2       i20           11      60000  Individual    Petrol            Manual   \n",
       "3      Alto            9      37000  Individual    Petrol            Manual   \n",
       "4  Ecosport            6      30000      Dealer    Diesel            Manual   \n",
       "\n",
       "   mileage  engine  max_power  seats  selling_price  \n",
       "0    19.70     796      46.30      5         120000  \n",
       "1    18.90    1197      82.00      5         550000  \n",
       "2    17.00    1197      80.00      5         215000  \n",
       "3    20.92     998      67.10      5         226000  \n",
       "4    22.77    1498      98.59      5         570000  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e61c202a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of Numerical Features : 7\n",
      "Num of Categorical Features : 4\n",
      "Num of Discrete Features : 2\n",
      "Num of Continuous Features : 5\n"
     ]
    }
   ],
   "source": [
    "num_features = [feature for feature in df.columns if df[feature].dtype != 'O']\n",
    "print(\"Num of Numerical Features :\", len(num_features))\n",
    "cat_features = [feature for feature in df.columns if df[feature].dtype == 'O']\n",
    "print(\"Num of Categorical Features :\", len(cat_features))\n",
    "discrete_feature = [feature for feature in num_features if len(df[feature].unique())<25]\n",
    "print(\"Num of Discrete Features :\", len(discrete_feature))\n",
    "continuous_feature = [feature for feature in num_features if feature not in discrete_feature]\n",
    "print(\"Num of Continuous Features :\", len(continuous_feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "12d10bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df.drop(columns=['selling_price'],axis=1)\n",
    "y = df['selling_price']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1912f543",
   "metadata": {},
   "source": [
    "## Feature Encoding and Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8ac549",
   "metadata": {},
   "source": [
    "#### One Hot Encoding for Columns which has lesser unique values not discreate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0240753b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "X['model'] = le.fit_transform(X['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0169b724",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = X.select_dtypes(exclude='object').columns\n",
    "ohehot_columns = ['fuel_type','transmission_type','seller_type']\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder,StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "numeric_transformer = StandardScaler()\n",
    "oh_transformer = OneHotEncoder(drop='first')\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        (\"OneHotEncoder\",oh_transformer,ohehot_columns),\n",
    "        (\"StandardScaler\",numeric_transformer,num_features)\n",
    "    ],remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "255744f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "766ff8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_test = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcaf9b3c",
   "metadata": {},
   "source": [
    "## Model Training and Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "df571d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression,Ridge,Lasso,ElasticNet\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import accuracy_score,mean_absolute_error,mean_squared_error,roc_auc_score,roc_curve,r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "70a86bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(true,predicted):\n",
    "    mea = mean_absolute_error(true,predicted)\n",
    "    mse = mean_squared_error(true,predicted)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2_scr = r2_score(true,predicted)\n",
    "    return mea,mse,rmse,r2_scr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7c33cb56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name : LinearRegression\n",
      "--------------------------------------------------\n",
      "Train MAE : 268101.60708299326, Test MAE : 279618.57941584237\n",
      "Train MSE : 306756099359.75964, Test MSE : 252550062888.56573\n",
      "Train RMSE : 553855.6665411664, Test RMSE : 502543.5930230986\n",
      "Train R2 : 0.6217719576765959, Test R2 : 0.6645109298852003\n",
      "\n",
      "\n",
      "Model Name : Ridge\n",
      "--------------------------------------------------\n",
      "Train MAE : 268060.0140124582, Test MAE : 279557.4540451886\n",
      "Train MSE : 306756818582.0534, Test MSE : 252540889637.0159\n",
      "Train RMSE : 553856.3158275379, Test RMSE : 502534.46611851\n",
      "Train R2 : 0.6217710708807318, Test R2 : 0.664523115689461\n",
      "\n",
      "\n",
      "Model Name : Lasso\n",
      "--------------------------------------------------\n",
      "Train MAE : 268099.22866122884, Test MAE : 279614.75677125243\n",
      "Train MSE : 306756104247.9428, Test MSE : 252549201782.8731\n",
      "Train RMSE : 553855.6709540336, Test RMSE : 502542.73627510836\n",
      "Train R2 : 0.6217719516495015, Test R2 : 0.6645120737833439\n",
      "\n",
      "\n",
      "Model Name : ElasticNet\n",
      "--------------------------------------------------\n",
      "Train MAE : 235335.54250977346, Test MAE : 247641.5340056213\n",
      "Train MSE : 349521738925.3462, Test MSE : 290253204518.2689\n",
      "Train RMSE : 591203.6357511227, Test RMSE : 538751.5239127114\n",
      "Train R2 : 0.5690422347294082, Test R2 : 0.6144258426708806\n",
      "\n",
      "\n",
      "Model Name : KNeighborsRegressor\n",
      "--------------------------------------------------\n",
      "Train MAE : 92495.19792342634, Test MAE : 112934.39020434642\n",
      "Train MSE : 103356413030.49968, Test MSE : 66442643222.713264\n",
      "Train RMSE : 321490.9221587752, Test RMSE : 257764.70515319443\n",
      "Train R2 : 0.8725622934843486, Test R2 : 0.9117371805977614\n",
      "\n",
      "\n",
      "Model Name : DecisionTreeRegressor\n",
      "--------------------------------------------------\n",
      "Train MAE : 5164.819922128488, Test MAE : 124724.12422964645\n",
      "Train MSE : 432524990.53644824, Test MSE : 91067413252.98682\n",
      "Train RMSE : 20797.23516567643, Test RMSE : 301773.77827271016\n",
      "Train R2 : 0.9994666998284044, Test R2 : 0.8790254833415526\n",
      "\n",
      "\n",
      "Model Name : RandomForestRegressor\n",
      "--------------------------------------------------\n",
      "Train MAE : 40071.023395730335, Test MAE : 101103.38270002515\n",
      "Train MSE : 17856271471.84306, Test MSE : 49641490397.64525\n",
      "Train RMSE : 133627.3604911923, Test RMSE : 222803.70373412836\n",
      "Train R2 : 0.9779833469779854, Test R2 : 0.9340559362285046\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"LinearRegression\":LinearRegression(),\n",
    "    \"Ridge\":Ridge(),\n",
    "    \"Lasso\":Lasso(),\n",
    "    \"ElasticNet\":ElasticNet(),\n",
    "    \"KNeighborsRegressor\":KNeighborsRegressor(),\n",
    "    \"DecisionTreeRegressor\":DecisionTreeRegressor(),\n",
    "    \"RandomForestRegressor\":RandomForestRegressor()\n",
    "}\n",
    "\n",
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "    model.fit(X_train,y_train)\n",
    "\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    model_train_mae, model_train_mse, model_train_rmse, model_train_r2 = evaluate_model(y_train,y_train_pred)\n",
    "    model_test_mae, model_test_mse, model_test_rmse, model_test_r2 = evaluate_model(y_test,y_test_pred)\n",
    "\n",
    "    print(f\"Model Name : {list(models.keys())[i]}\")\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(f\"Train MAE : {model_train_mae}, Test MAE : {model_test_mae}\")\n",
    "    print(f\"Train MSE : {model_train_mse}, Test MSE : {model_test_mse}\")\n",
    "    print(f\"Train RMSE : {model_train_rmse}, Test RMSE : {model_test_rmse}\")\n",
    "    print(f\"Train R2 : {model_train_r2}, Test R2 : {model_test_r2}\")\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "99fa3d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_params = {'n_neighbors': [1,2,5,6,7,9,10,15,20,30,35,40,50]}\n",
    "rf_params = {'n_estimators':[50,100,200,300,400,500,600,700],'max_depth':[None,5,10,15],'min_samples_split':[2,5,10],'min_samples_leaf':[1,2,4]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "efb261c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "randomcv_models = [\n",
    "    ('KNeighborsRegressor',KNeighborsRegressor(),knn_params),\n",
    "    ('RandomForestRegressor',RandomForestRegressor(),rf_params)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f7d28d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mkuma\\OneDrive\\Desktop\\ML\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:317: UserWarning: The total space of parameters 13 is smaller than n_iter=100. Running 13 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mkuma\\OneDrive\\Desktop\\ML\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:811: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 13 candidates, totalling 65 fits\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mkuma\\OneDrive\\Desktop\\ML\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:811: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "cv = StratifiedKFold(n_splits=5,shuffle=True,random_state=42)\n",
    "model_params = {}\n",
    "for name,model,params in randomcv_models:\n",
    "    random_cv = RandomizedSearchCV(estimator=model,param_distributions=params,n_iter=100,scoring='neg_mean_squared_error',cv=cv,verbose=3,n_jobs=-1,refit=True)\n",
    "    random_cv.fit(X_train,y_train)\n",
    "    model_params[name] = random_cv.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "42eaaad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for KNeighborsRegressor: {'n_neighbors': 5}\n",
      "Best parameters for RandomForestRegressor: {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': None}\n"
     ]
    }
   ],
   "source": [
    "for model_name in model_params:\n",
    "    print(f\"Best parameters for {model_name}: {model_params[model_name]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "aee2fda8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name : Random Forest Regressor\n",
      "--------------------------------------------------\n",
      "Train MAE : 39500.75152971326, Test MAE : 101618.21861709039\n",
      "Train MSE : 16383693385.688322, Test MSE : 52072643383.76283\n",
      "Train RMSE : 127998.80228224138, Test RMSE : 228194.31058587512\n",
      "Train R2 : 0.9797990250618349, Test R2 : 0.9308263775212502\n",
      "\n",
      "\n",
      "Model Name : KNeighborsRegressor\n",
      "--------------------------------------------------\n",
      "Train MAE : 92495.19792342634, Test MAE : 112934.39020434642\n",
      "Train MSE : 103356413030.49968, Test MSE : 66442643222.713264\n",
      "Train RMSE : 321490.9221587752, Test RMSE : 257764.70515319443\n",
      "Train R2 : 0.8725622934843486, Test R2 : 0.9117371805977614\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"Random Forest Regressor\":RandomForestRegressor(n_estimators=200,min_samples_split=2,min_samples_leaf=1,max_depth=None),\n",
    "    \"KNeighborsRegressor\":KNeighborsRegressor(n_neighbors=5)\n",
    "}\n",
    "\n",
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "    model.fit(X_train,y_train)\n",
    "\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    model_train_mae, model_train_mse, model_train_rmse, model_train_r2 = evaluate_model(y_train,y_train_pred)\n",
    "    model_test_mae, model_test_mse, model_test_rmse, model_test_r2 = evaluate_model(y_test,y_test_pred)\n",
    "\n",
    "    print(f\"Model Name : {list(models.keys())[i]}\")\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(f\"Train MAE : {model_train_mae}, Test MAE : {model_test_mae}\")\n",
    "    print(f\"Train MSE : {model_train_mse}, Test MSE : {model_test_mse}\")\n",
    "    print(f\"Train RMSE : {model_train_rmse}, Test RMSE : {model_test_rmse}\")\n",
    "    print(f\"Train R2 : {model_train_r2}, Test R2 : {model_test_r2}\")\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2536a988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Hyperparameter Grids for Top Performing Models\n",
    "# Based on industry best practices and Kaggle competitions\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import time\n",
    "\n",
    "# 1. Decision Tree Regressor\n",
    "decision_tree_params = {\n",
    "    'max_depth': [3, 5, 7, 10, 15, 20, None],\n",
    "    'min_samples_split': [2, 5, 10, 20],\n",
    "    'min_samples_leaf': [1, 2, 4, 8],\n",
    "    'max_features': ['auto', 'sqrt', 'log2', None],\n",
    "    'criterion': ['squared_error', 'friedman_mse'],\n",
    "    'splitter': ['best', 'random']\n",
    "}\n",
    "\n",
    "# 2. Random Forest Regressor (Most Important Parameters)\n",
    "random_forest_params = {\n",
    "    'n_estimators': [50, 100, 200, 300, 500],\n",
    "    'max_depth': [3, 5, 7, 10, 15, 20, None],\n",
    "    'min_samples_split': [2, 5, 10, 20],\n",
    "    'min_samples_leaf': [1, 2, 4, 8],\n",
    "    'max_features': ['auto', 'sqrt', 'log2', 0.3, 0.5, 0.7],\n",
    "    'bootstrap': [True, False],\n",
    "    'oob_score': [True, False]  # Only when bootstrap=True\n",
    "}\n",
    "\n",
    "# 3. LightGBM Regressor (Gradient Boosting)\n",
    "lightgbm_params = {\n",
    "    'n_estimators': [100, 200, 300, 500, 1000],\n",
    "    'max_depth': [3, 5, 7, 10, 15, -1],  # -1 means no limit\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.15, 0.2],\n",
    "    'num_leaves': [15, 31, 50, 100, 200],\n",
    "    'subsample': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'reg_alpha': [0, 0.1, 0.5, 1.0],  # L1 regularization\n",
    "    'reg_lambda': [0, 0.1, 0.5, 1.0], # L2 regularization\n",
    "    'min_child_samples': [5, 10, 20, 30]\n",
    "}\n",
    "\n",
    "# 4. XGBoost Regressor\n",
    "xgboost_params = {\n",
    "    'n_estimators': [100, 200, 300, 500, 1000],\n",
    "    'max_depth': [3, 4, 5, 6, 7, 8],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.15, 0.2],\n",
    "    'subsample': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'colsample_bylevel': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'reg_alpha': [0, 0.1, 0.5, 1.0],  # L1 regularization\n",
    "    'reg_lambda': [0, 0.1, 0.5, 1.0], # L2 regularization\n",
    "    'gamma': [0, 0.1, 0.2, 0.5],      # Minimum split loss\n",
    "    'min_child_weight': [1, 3, 5, 7]\n",
    "}\n",
    "\n",
    "# 5. CatBoost Regressor\n",
    "catboost_params = {\n",
    "    'iterations': [100, 200, 300, 500, 1000],\n",
    "    'depth': [3, 4, 5, 6, 7, 8, 10],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.15, 0.2],\n",
    "    'l2_leaf_reg': [1, 3, 5, 7, 9],    # L2 regularization\n",
    "    'border_count': [32, 64, 128, 255], # Feature discretization\n",
    "    'bagging_temperature': [0, 0.5, 1.0],\n",
    "    'random_strength': [0, 1, 2, 3],\n",
    "    'od_type': ['IncToDec', 'Iter'],    # Overfitting detection\n",
    "    'od_wait': [10, 20, 30, 50]\n",
    "}\n",
    "\n",
    "print(\"ðŸŽ¯ HYPERPARAMETER GRIDS FOR BEST MODELS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Decision Tree parameters: {len(decision_tree_params)} hyperparameters\")\n",
    "print(f\"Random Forest parameters: {len(random_forest_params)} hyperparameters\")\n",
    "print(f\"LightGBM parameters: {len(lightgbm_params)} hyperparameters\")\n",
    "print(f\"XGBoost parameters: {len(xgboost_params)} hyperparameters\")\n",
    "print(f\"CatBoost parameters: {len(catboost_params)} hyperparameters\")\n",
    "\n",
    "# Calculate total combinations (for reference)\n",
    "dt_combinations = np.prod([len(v) for v in decision_tree_params.values()])\n",
    "rf_combinations = np.prod([len(v) for v in random_forest_params.values()])\n",
    "lgb_combinations = np.prod([len(v) for v in lightgbm_params.values()])\n",
    "xgb_combinations = np.prod([len(v) for v in xgboost_params.values()])\n",
    "cat_combinations = np.prod([len(v) for v in catboost_params.values()])\n",
    "\n",
    "print(\"\\nðŸ“Š TOTAL POSSIBLE COMBINATIONS:\")\n",
    "print(f\"Decision Tree: {dt_combinations:,}\")\n",
    "print(f\"Random Forest: {rf_combinations:,}\")\n",
    "print(f\"LightGBM: {lgb_combinations:,}\")\n",
    "print(f\"XGBoost: {xgb_combinations:,}\")\n",
    "print(f\"CatBoost: {cat_combinations:,}\")\n",
    "\n",
    "print(\"\\nðŸ’¡ RECOMMENDATIONS:\")\n",
    "print(\"â€¢ Use RandomizedSearchCV with n_iter=100-200 for faster results\")\n",
    "print(\"â€¢ Use GridSearchCV only for final tuning with smaller parameter space\")\n",
    "print(\"â€¢ Start with fewer parameters, then expand based on results\")\n",
    "print(\"â€¢ Use early stopping for tree-based models to prevent overfitting\")\n",
    "\n",
    "# PRACTICAL IMPLEMENTATION - REDUCED PARAMETER GRIDS FOR FASTER SEARCH\n",
    "# Use these for initial hyperparameter tuning\n",
    "\n",
    "# Reduced grids for faster RandomizedSearchCV\n",
    "quick_decision_tree_params = {\n",
    "    'max_depth': [5, 10, 15, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', None]\n",
    "}\n",
    "\n",
    "quick_random_forest_params = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [5, 10, 15, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 0.5]\n",
    "}\n",
    "\n",
    "quick_lightgbm_params = {\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'max_depth': [5, 7, 10, -1],\n",
    "    'learning_rate': [0.05, 0.1, 0.15],\n",
    "    'num_leaves': [31, 50, 100],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "quick_xgboost_params = {\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.05, 0.1, 0.15],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0],\n",
    "    'reg_alpha': [0, 0.1, 0.5]\n",
    "}\n",
    "\n",
    "quick_catboost_params = {\n",
    "    'iterations': [100, 200, 500],\n",
    "    'depth': [4, 6, 8],\n",
    "    'learning_rate': [0.05, 0.1, 0.15],\n",
    "    'l2_leaf_reg': [1, 3, 5]\n",
    "}\n",
    "\n",
    "print(\"\\nâš¡ QUICK SEARCH GRIDS (Recommended for initial tuning)\")\n",
    "print(\"=\"*55)\n",
    "print(\"Use these reduced grids with RandomizedSearchCV for faster results:\")\n",
    "print(f\"â€¢ Quick Decision Tree: {np.prod([len(v) for v in quick_decision_tree_params.values()]):,} combinations\")\n",
    "print(f\"â€¢ Quick Random Forest: {np.prod([len(v) for v in quick_random_forest_params.values()]):,} combinations\")\n",
    "print(f\"â€¢ Quick LightGBM: {np.prod([len(v) for v in quick_lightgbm_params.values()]):,} combinations\")\n",
    "print(f\"â€¢ Quick XGBoost: {np.prod([len(v) for v in quick_xgboost_params.values()]):,} combinations\")\n",
    "print(f\"â€¢ Quick CatBoost: {np.prod([len(v) for v in quick_catboost_params.values()]):,} combinations\")\n",
    "\n",
    "# EXAMPLE IMPLEMENTATION WITH RANDOMIZEDSEARCHCV\n",
    "def run_hyperparameter_tuning(model, param_grid, model_name, X_train, y_train, n_iter=50):\n",
    "    \"\"\"\n",
    "    Run hyperparameter tuning using RandomizedSearchCV\n",
    "    \"\"\"\n",
    "    print(f\"\\nðŸ” Tuning {model_name}...\")\n",
    "\n",
    "    # Set up cross-validation\n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    # Create RandomizedSearchCV\n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=model,\n",
    "        param_distributions=param_grid,\n",
    "        n_iter=n_iter,  # Number of parameter combinations to try\n",
    "        cv=cv,\n",
    "        scoring='r2',  # or 'neg_mean_squared_error'\n",
    "        n_jobs=-1,     # Use all CPU cores\n",
    "        verbose=1,     # Print progress\n",
    "        random_state=42,\n",
    "        refit=True     # Refit on best parameters\n",
    "    )\n",
    "\n",
    "    # Fit the model\n",
    "    start_time = time.time()\n",
    "    random_search.fit(X_train, y_train)\n",
    "    end_time = time.time()\n",
    "\n",
    "    print(f\"â±ï¸  Tuning completed in {end_time - start_time:.2f} seconds\")\n",
    "    print(f\"ðŸ† Best Score (R2): {random_search.best_score_:.4f}\")\n",
    "    print(f\"ðŸŽ¯ Best Parameters: {random_search.best_params_}\")\n",
    "\n",
    "    return random_search.best_estimator_, random_search.best_params_\n",
    "\n",
    "# Example usage (uncomment to run):\n",
    "#\n",
    "# # Tune Random Forest\n",
    "# best_rf, best_rf_params = run_hyperparameter_tuning(\n",
    "#     model=RandomForestRegressor(random_state=42),\n",
    "#     param_grid=quick_random_forest_params,\n",
    "#     model_name=\"Random Forest\",\n",
    "#     X_train=X_train,\n",
    "#     y_train=y_train,\n",
    "#     n_iter=50\n",
    "# )\n",
    "#\n",
    "# # Tune Decision Tree\n",
    "# best_dt, best_dt_params = run_hyperparameter_tuning(\n",
    "#     model=DecisionTreeRegressor(random_state=42),\n",
    "#     param_grid=quick_decision_tree_params,\n",
    "#     model_name=\"Decision Tree\",\n",
    "#     X_train=X_train,\n",
    "#     y_train=y_train,\n",
    "#     n_iter=30\n",
    "# )\n",
    "\n",
    "print(\"\\nðŸ“ IMPLEMENTATION NOTES:\")\n",
    "print(\"1. Start with 'quick_' parameter grids for faster results\")\n",
    "print(\"2. Use n_iter=50-100 for RandomizedSearchCV\")\n",
    "print(\"3. Increase n_iter for final tuning\")\n",
    "print(\"4. Use the full parameter grids for competition-level performance\")\n",
    "print(\"5. Consider using early_stopping_rounds for XGBoost/LightGBM/CatBoost\")\n",
    "print(\"6. For regression tasks, use 'r2' or 'neg_mean_squared_error' as scoring\")\n",
    "print(\"7. Use KFold instead of StratifiedKFold for regression problems\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
