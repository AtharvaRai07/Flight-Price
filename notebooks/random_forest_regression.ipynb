{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4eebc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "916436ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>car_name</th>\n",
       "      <th>brand</th>\n",
       "      <th>model</th>\n",
       "      <th>vehicle_age</th>\n",
       "      <th>km_driven</th>\n",
       "      <th>seller_type</th>\n",
       "      <th>fuel_type</th>\n",
       "      <th>transmission_type</th>\n",
       "      <th>mileage</th>\n",
       "      <th>engine</th>\n",
       "      <th>max_power</th>\n",
       "      <th>seats</th>\n",
       "      <th>selling_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Maruti Alto</td>\n",
       "      <td>Maruti</td>\n",
       "      <td>Alto</td>\n",
       "      <td>9</td>\n",
       "      <td>120000</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Manual</td>\n",
       "      <td>19.70</td>\n",
       "      <td>796</td>\n",
       "      <td>46.30</td>\n",
       "      <td>5</td>\n",
       "      <td>120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hyundai Grand</td>\n",
       "      <td>Hyundai</td>\n",
       "      <td>Grand</td>\n",
       "      <td>5</td>\n",
       "      <td>20000</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Manual</td>\n",
       "      <td>18.90</td>\n",
       "      <td>1197</td>\n",
       "      <td>82.00</td>\n",
       "      <td>5</td>\n",
       "      <td>550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hyundai i20</td>\n",
       "      <td>Hyundai</td>\n",
       "      <td>i20</td>\n",
       "      <td>11</td>\n",
       "      <td>60000</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Manual</td>\n",
       "      <td>17.00</td>\n",
       "      <td>1197</td>\n",
       "      <td>80.00</td>\n",
       "      <td>5</td>\n",
       "      <td>215000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Maruti Alto</td>\n",
       "      <td>Maruti</td>\n",
       "      <td>Alto</td>\n",
       "      <td>9</td>\n",
       "      <td>37000</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Manual</td>\n",
       "      <td>20.92</td>\n",
       "      <td>998</td>\n",
       "      <td>67.10</td>\n",
       "      <td>5</td>\n",
       "      <td>226000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ford Ecosport</td>\n",
       "      <td>Ford</td>\n",
       "      <td>Ecosport</td>\n",
       "      <td>6</td>\n",
       "      <td>30000</td>\n",
       "      <td>Dealer</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Manual</td>\n",
       "      <td>22.77</td>\n",
       "      <td>1498</td>\n",
       "      <td>98.59</td>\n",
       "      <td>5</td>\n",
       "      <td>570000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        car_name    brand     model  vehicle_age  km_driven seller_type  \\\n",
       "0    Maruti Alto   Maruti      Alto            9     120000  Individual   \n",
       "1  Hyundai Grand  Hyundai     Grand            5      20000  Individual   \n",
       "2    Hyundai i20  Hyundai       i20           11      60000  Individual   \n",
       "3    Maruti Alto   Maruti      Alto            9      37000  Individual   \n",
       "4  Ford Ecosport     Ford  Ecosport            6      30000      Dealer   \n",
       "\n",
       "  fuel_type transmission_type  mileage  engine  max_power  seats  \\\n",
       "0    Petrol            Manual    19.70     796      46.30      5   \n",
       "1    Petrol            Manual    18.90    1197      82.00      5   \n",
       "2    Petrol            Manual    17.00    1197      80.00      5   \n",
       "3    Petrol            Manual    20.92     998      67.10      5   \n",
       "4    Diesel            Manual    22.77    1498      98.59      5   \n",
       "\n",
       "   selling_price  \n",
       "0         120000  \n",
       "1         550000  \n",
       "2         215000  \n",
       "3         226000  \n",
       "4         570000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('cardekho_imputated.csv',index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913eea79",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d7e11c",
   "metadata": {},
   "source": [
    "#### Handling Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "864c47b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "car_name             0\n",
       "brand                0\n",
       "model                0\n",
       "vehicle_age          0\n",
       "km_driven            0\n",
       "seller_type          0\n",
       "fuel_type            0\n",
       "transmission_type    0\n",
       "mileage              0\n",
       "engine               0\n",
       "max_power            0\n",
       "seats                0\n",
       "selling_price        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ba122b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['car_name','brand'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63630089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>vehicle_age</th>\n",
       "      <th>km_driven</th>\n",
       "      <th>seller_type</th>\n",
       "      <th>fuel_type</th>\n",
       "      <th>transmission_type</th>\n",
       "      <th>mileage</th>\n",
       "      <th>engine</th>\n",
       "      <th>max_power</th>\n",
       "      <th>seats</th>\n",
       "      <th>selling_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alto</td>\n",
       "      <td>9</td>\n",
       "      <td>120000</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Manual</td>\n",
       "      <td>19.70</td>\n",
       "      <td>796</td>\n",
       "      <td>46.30</td>\n",
       "      <td>5</td>\n",
       "      <td>120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Grand</td>\n",
       "      <td>5</td>\n",
       "      <td>20000</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Manual</td>\n",
       "      <td>18.90</td>\n",
       "      <td>1197</td>\n",
       "      <td>82.00</td>\n",
       "      <td>5</td>\n",
       "      <td>550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i20</td>\n",
       "      <td>11</td>\n",
       "      <td>60000</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Manual</td>\n",
       "      <td>17.00</td>\n",
       "      <td>1197</td>\n",
       "      <td>80.00</td>\n",
       "      <td>5</td>\n",
       "      <td>215000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alto</td>\n",
       "      <td>9</td>\n",
       "      <td>37000</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Manual</td>\n",
       "      <td>20.92</td>\n",
       "      <td>998</td>\n",
       "      <td>67.10</td>\n",
       "      <td>5</td>\n",
       "      <td>226000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ecosport</td>\n",
       "      <td>6</td>\n",
       "      <td>30000</td>\n",
       "      <td>Dealer</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Manual</td>\n",
       "      <td>22.77</td>\n",
       "      <td>1498</td>\n",
       "      <td>98.59</td>\n",
       "      <td>5</td>\n",
       "      <td>570000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model  vehicle_age  km_driven seller_type fuel_type transmission_type  \\\n",
       "0      Alto            9     120000  Individual    Petrol            Manual   \n",
       "1     Grand            5      20000  Individual    Petrol            Manual   \n",
       "2       i20           11      60000  Individual    Petrol            Manual   \n",
       "3      Alto            9      37000  Individual    Petrol            Manual   \n",
       "4  Ecosport            6      30000      Dealer    Diesel            Manual   \n",
       "\n",
       "   mileage  engine  max_power  seats  selling_price  \n",
       "0    19.70     796      46.30      5         120000  \n",
       "1    18.90    1197      82.00      5         550000  \n",
       "2    17.00    1197      80.00      5         215000  \n",
       "3    20.92     998      67.10      5         226000  \n",
       "4    22.77    1498      98.59      5         570000  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e61c202a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of Numerical Features : 7\n",
      "Num of Categorical Features : 4\n",
      "Num of Discrete Features : 2\n",
      "Num of Continuous Features : 5\n"
     ]
    }
   ],
   "source": [
    "num_features = [feature for feature in df.columns if df[feature].dtype != 'O']\n",
    "print(\"Num of Numerical Features :\", len(num_features))\n",
    "cat_features = [feature for feature in df.columns if df[feature].dtype == 'O']\n",
    "print(\"Num of Categorical Features :\", len(cat_features))\n",
    "discrete_feature = [feature for feature in num_features if len(df[feature].unique())<25]\n",
    "print(\"Num of Discrete Features :\", len(discrete_feature))\n",
    "continuous_feature = [feature for feature in num_features if feature not in discrete_feature]\n",
    "print(\"Num of Continuous Features :\", len(continuous_feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "12d10bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df.drop(columns=['selling_price'],axis=1)\n",
    "y = df['selling_price']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1912f543",
   "metadata": {},
   "source": [
    "## Feature Encoding and Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8ac549",
   "metadata": {},
   "source": [
    "#### One Hot Encoding for Columns which has lesser unique values not discreate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0240753b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "X['model'] = le.fit_transform(X['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0169b724",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = X.select_dtypes(exclude='object').columns\n",
    "ohehot_columns = ['fuel_type','transmission_type','seller_type']\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder,StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "numeric_transformer = StandardScaler()\n",
    "oh_transformer = OneHotEncoder(drop='first')\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        (\"OneHotEncoder\",oh_transformer,ohehot_columns),\n",
    "        (\"StandardScaler\",numeric_transformer,num_features)\n",
    "    ],remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "255744f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "766ff8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_test = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcaf9b3c",
   "metadata": {},
   "source": [
    "## Model Training and Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "df571d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression,Ridge,Lasso,ElasticNet\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import accuracy_score,mean_absolute_error,mean_squared_error,roc_auc_score,roc_curve,r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "70a86bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(true,predicted):\n",
    "    mea = mean_absolute_error(true,predicted)\n",
    "    mse = mean_squared_error(true,predicted)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2_scr = r2_score(true,predicted)\n",
    "    return mea,mse,rmse,r2_scr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7c33cb56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name : LinearRegression\n",
      "--------------------------------------------------\n",
      "Train MAE : 268101.60708299326, Test MAE : 279618.57941584237\n",
      "Train MSE : 306756099359.75964, Test MSE : 252550062888.56573\n",
      "Train RMSE : 553855.6665411664, Test RMSE : 502543.5930230986\n",
      "Train R2 : 0.6217719576765959, Test R2 : 0.6645109298852003\n",
      "\n",
      "\n",
      "Model Name : Ridge\n",
      "--------------------------------------------------\n",
      "Train MAE : 268060.0140124582, Test MAE : 279557.4540451886\n",
      "Train MSE : 306756818582.0534, Test MSE : 252540889637.0159\n",
      "Train RMSE : 553856.3158275379, Test RMSE : 502534.46611851\n",
      "Train R2 : 0.6217710708807318, Test R2 : 0.664523115689461\n",
      "\n",
      "\n",
      "Model Name : Lasso\n",
      "--------------------------------------------------\n",
      "Train MAE : 268099.22866122884, Test MAE : 279614.75677125243\n",
      "Train MSE : 306756104247.9428, Test MSE : 252549201782.8731\n",
      "Train RMSE : 553855.6709540336, Test RMSE : 502542.73627510836\n",
      "Train R2 : 0.6217719516495015, Test R2 : 0.6645120737833439\n",
      "\n",
      "\n",
      "Model Name : ElasticNet\n",
      "--------------------------------------------------\n",
      "Train MAE : 235335.54250977346, Test MAE : 247641.5340056213\n",
      "Train MSE : 349521738925.3462, Test MSE : 290253204518.2689\n",
      "Train RMSE : 591203.6357511227, Test RMSE : 538751.5239127114\n",
      "Train R2 : 0.5690422347294082, Test R2 : 0.6144258426708806\n",
      "\n",
      "\n",
      "Model Name : KNeighborsRegressor\n",
      "--------------------------------------------------\n",
      "Train MAE : 92495.19792342634, Test MAE : 112934.39020434642\n",
      "Train MSE : 103356413030.49968, Test MSE : 66442643222.713264\n",
      "Train RMSE : 321490.9221587752, Test RMSE : 257764.70515319443\n",
      "Train R2 : 0.8725622934843486, Test R2 : 0.9117371805977614\n",
      "\n",
      "\n",
      "Model Name : DecisionTreeRegressor\n",
      "--------------------------------------------------\n",
      "Train MAE : 5164.819922128488, Test MAE : 124724.12422964645\n",
      "Train MSE : 432524990.53644824, Test MSE : 91067413252.98682\n",
      "Train RMSE : 20797.23516567643, Test RMSE : 301773.77827271016\n",
      "Train R2 : 0.9994666998284044, Test R2 : 0.8790254833415526\n",
      "\n",
      "\n",
      "Model Name : RandomForestRegressor\n",
      "--------------------------------------------------\n",
      "Train MAE : 40071.023395730335, Test MAE : 101103.38270002515\n",
      "Train MSE : 17856271471.84306, Test MSE : 49641490397.64525\n",
      "Train RMSE : 133627.3604911923, Test RMSE : 222803.70373412836\n",
      "Train R2 : 0.9779833469779854, Test R2 : 0.9340559362285046\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"LinearRegression\":LinearRegression(),\n",
    "    \"Ridge\":Ridge(),\n",
    "    \"Lasso\":Lasso(),\n",
    "    \"ElasticNet\":ElasticNet(),\n",
    "    \"KNeighborsRegressor\":KNeighborsRegressor(),\n",
    "    \"DecisionTreeRegressor\":DecisionTreeRegressor(),\n",
    "    \"RandomForestRegressor\":RandomForestRegressor()\n",
    "}\n",
    "\n",
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "    model.fit(X_train,y_train)\n",
    "\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    model_train_mae, model_train_mse, model_train_rmse, model_train_r2 = evaluate_model(y_train,y_train_pred)\n",
    "    model_test_mae, model_test_mse, model_test_rmse, model_test_r2 = evaluate_model(y_test,y_test_pred)\n",
    "\n",
    "    print(f\"Model Name : {list(models.keys())[i]}\")\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(f\"Train MAE : {model_train_mae}, Test MAE : {model_test_mae}\")\n",
    "    print(f\"Train MSE : {model_train_mse}, Test MSE : {model_test_mse}\")\n",
    "    print(f\"Train RMSE : {model_train_rmse}, Test RMSE : {model_test_rmse}\")\n",
    "    print(f\"Train R2 : {model_train_r2}, Test R2 : {model_test_r2}\")\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "99fa3d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_params = {'n_neighbors': [1,2,5,6,7,9,10,15,20,30,35,40,50]}\n",
    "rf_params = {'n_estimators':[50,100,200,300,400,500,600,700],'max_depth':[None,5,10,15],'min_samples_split':[2,5,10],'min_samples_leaf':[1,2,4]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "efb261c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "randomcv_models = [\n",
    "    ('KNeighborsRegressor',KNeighborsRegressor(),knn_params),\n",
    "    ('RandomForestRegressor',RandomForestRegressor(),rf_params)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f7d28d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mkuma\\OneDrive\\Desktop\\ML\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:317: UserWarning: The total space of parameters 13 is smaller than n_iter=100. Running 13 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mkuma\\OneDrive\\Desktop\\ML\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:811: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 13 candidates, totalling 65 fits\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mkuma\\OneDrive\\Desktop\\ML\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:811: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "cv = StratifiedKFold(n_splits=5,shuffle=True,random_state=42)\n",
    "model_params = {}\n",
    "for name,model,params in randomcv_models:\n",
    "    random_cv = RandomizedSearchCV(estimator=model,param_distributions=params,n_iter=100,scoring='neg_mean_squared_error',cv=cv,verbose=3,n_jobs=-1,refit=True)\n",
    "    random_cv.fit(X_train,y_train)\n",
    "    model_params[name] = random_cv.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "42eaaad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for KNeighborsRegressor: {'n_neighbors': 5}\n",
      "Best parameters for RandomForestRegressor: {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': None}\n"
     ]
    }
   ],
   "source": [
    "for model_name in model_params:\n",
    "    print(f\"Best parameters for {model_name}: {model_params[model_name]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "aee2fda8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name : Random Forest Regressor\n",
      "--------------------------------------------------\n",
      "Train MAE : 39500.75152971326, Test MAE : 101618.21861709039\n",
      "Train MSE : 16383693385.688322, Test MSE : 52072643383.76283\n",
      "Train RMSE : 127998.80228224138, Test RMSE : 228194.31058587512\n",
      "Train R2 : 0.9797990250618349, Test R2 : 0.9308263775212502\n",
      "\n",
      "\n",
      "Model Name : KNeighborsRegressor\n",
      "--------------------------------------------------\n",
      "Train MAE : 92495.19792342634, Test MAE : 112934.39020434642\n",
      "Train MSE : 103356413030.49968, Test MSE : 66442643222.713264\n",
      "Train RMSE : 321490.9221587752, Test RMSE : 257764.70515319443\n",
      "Train R2 : 0.8725622934843486, Test R2 : 0.9117371805977614\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"Random Forest Regressor\":RandomForestRegressor(n_estimators=200,min_samples_split=2,min_samples_leaf=1,max_depth=None),\n",
    "    \"KNeighborsRegressor\":KNeighborsRegressor(n_neighbors=5)\n",
    "}\n",
    "\n",
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "    model.fit(X_train,y_train)\n",
    "\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    model_train_mae, model_train_mse, model_train_rmse, model_train_r2 = evaluate_model(y_train,y_train_pred)\n",
    "    model_test_mae, model_test_mse, model_test_rmse, model_test_r2 = evaluate_model(y_test,y_test_pred)\n",
    "\n",
    "    print(f\"Model Name : {list(models.keys())[i]}\")\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(f\"Train MAE : {model_train_mae}, Test MAE : {model_test_mae}\")\n",
    "    print(f\"Train MSE : {model_train_mse}, Test MSE : {model_test_mse}\")\n",
    "    print(f\"Train RMSE : {model_train_rmse}, Test RMSE : {model_test_rmse}\")\n",
    "    print(f\"Train R2 : {model_train_r2}, Test R2 : {model_test_r2}\")\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2536a988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Hyperparameter Grids for Top Performing Models\n",
    "# Based on industry best practices and Kaggle competitions\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import time\n",
    "\n",
    "# 1. Decision Tree Regressor\n",
    "decision_tree_params = {\n",
    "    'max_depth': [3, 5, 7, 10, 15, 20, None],\n",
    "    'min_samples_split': [2, 5, 10, 20],\n",
    "    'min_samples_leaf': [1, 2, 4, 8],\n",
    "    'max_features': ['auto', 'sqrt', 'log2', None],\n",
    "    'criterion': ['squared_error', 'friedman_mse'],\n",
    "    'splitter': ['best', 'random']\n",
    "}\n",
    "\n",
    "# 2. Random Forest Regressor (Most Important Parameters)\n",
    "random_forest_params = {\n",
    "    'n_estimators': [50, 100, 200, 300, 500],\n",
    "    'max_depth': [3, 5, 7, 10, 15, 20, None],\n",
    "    'min_samples_split': [2, 5, 10, 20],\n",
    "    'min_samples_leaf': [1, 2, 4, 8],\n",
    "    'max_features': ['auto', 'sqrt', 'log2', 0.3, 0.5, 0.7],\n",
    "    'bootstrap': [True, False],\n",
    "    'oob_score': [True, False]  # Only when bootstrap=True\n",
    "}\n",
    "\n",
    "# 3. LightGBM Regressor (Gradient Boosting)\n",
    "lightgbm_params = {\n",
    "    'n_estimators': [100, 200, 300, 500, 1000],\n",
    "    'max_depth': [3, 5, 7, 10, 15, -1],  # -1 means no limit\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.15, 0.2],\n",
    "    'num_leaves': [15, 31, 50, 100, 200],\n",
    "    'subsample': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'reg_alpha': [0, 0.1, 0.5, 1.0],  # L1 regularization\n",
    "    'reg_lambda': [0, 0.1, 0.5, 1.0], # L2 regularization\n",
    "    'min_child_samples': [5, 10, 20, 30]\n",
    "}\n",
    "\n",
    "# 4. XGBoost Regressor\n",
    "xgboost_params = {\n",
    "    'n_estimators': [100, 200, 300, 500, 1000],\n",
    "    'max_depth': [3, 4, 5, 6, 7, 8],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.15, 0.2],\n",
    "    'subsample': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'colsample_bylevel': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'reg_alpha': [0, 0.1, 0.5, 1.0],  # L1 regularization\n",
    "    'reg_lambda': [0, 0.1, 0.5, 1.0], # L2 regularization\n",
    "    'gamma': [0, 0.1, 0.2, 0.5],      # Minimum split loss\n",
    "    'min_child_weight': [1, 3, 5, 7]\n",
    "}\n",
    "\n",
    "# 5. CatBoost Regressor\n",
    "catboost_params = {\n",
    "    'iterations': [100, 200, 300, 500, 1000],\n",
    "    'depth': [3, 4, 5, 6, 7, 8, 10],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.15, 0.2],\n",
    "    'l2_leaf_reg': [1, 3, 5, 7, 9],    # L2 regularization\n",
    "    'border_count': [32, 64, 128, 255], # Feature discretization\n",
    "    'bagging_temperature': [0, 0.5, 1.0],\n",
    "    'random_strength': [0, 1, 2, 3],\n",
    "    'od_type': ['IncToDec', 'Iter'],    # Overfitting detection\n",
    "    'od_wait': [10, 20, 30, 50]\n",
    "}\n",
    "\n",
    "print(\"🎯 HYPERPARAMETER GRIDS FOR BEST MODELS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Decision Tree parameters: {len(decision_tree_params)} hyperparameters\")\n",
    "print(f\"Random Forest parameters: {len(random_forest_params)} hyperparameters\")\n",
    "print(f\"LightGBM parameters: {len(lightgbm_params)} hyperparameters\")\n",
    "print(f\"XGBoost parameters: {len(xgboost_params)} hyperparameters\")\n",
    "print(f\"CatBoost parameters: {len(catboost_params)} hyperparameters\")\n",
    "\n",
    "# Calculate total combinations (for reference)\n",
    "dt_combinations = np.prod([len(v) for v in decision_tree_params.values()])\n",
    "rf_combinations = np.prod([len(v) for v in random_forest_params.values()])\n",
    "lgb_combinations = np.prod([len(v) for v in lightgbm_params.values()])\n",
    "xgb_combinations = np.prod([len(v) for v in xgboost_params.values()])\n",
    "cat_combinations = np.prod([len(v) for v in catboost_params.values()])\n",
    "\n",
    "print(\"\\n📊 TOTAL POSSIBLE COMBINATIONS:\")\n",
    "print(f\"Decision Tree: {dt_combinations:,}\")\n",
    "print(f\"Random Forest: {rf_combinations:,}\")\n",
    "print(f\"LightGBM: {lgb_combinations:,}\")\n",
    "print(f\"XGBoost: {xgb_combinations:,}\")\n",
    "print(f\"CatBoost: {cat_combinations:,}\")\n",
    "\n",
    "print(\"\\n💡 RECOMMENDATIONS:\")\n",
    "print(\"• Use RandomizedSearchCV with n_iter=100-200 for faster results\")\n",
    "print(\"• Use GridSearchCV only for final tuning with smaller parameter space\")\n",
    "print(\"• Start with fewer parameters, then expand based on results\")\n",
    "print(\"• Use early stopping for tree-based models to prevent overfitting\")\n",
    "\n",
    "# PRACTICAL IMPLEMENTATION - REDUCED PARAMETER GRIDS FOR FASTER SEARCH\n",
    "# Use these for initial hyperparameter tuning\n",
    "\n",
    "# Reduced grids for faster RandomizedSearchCV\n",
    "quick_decision_tree_params = {\n",
    "    'max_depth': [5, 10, 15, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', None]\n",
    "}\n",
    "\n",
    "quick_random_forest_params = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [5, 10, 15, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 0.5]\n",
    "}\n",
    "\n",
    "quick_lightgbm_params = {\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'max_depth': [5, 7, 10, -1],\n",
    "    'learning_rate': [0.05, 0.1, 0.15],\n",
    "    'num_leaves': [31, 50, 100],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "quick_xgboost_params = {\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.05, 0.1, 0.15],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0],\n",
    "    'reg_alpha': [0, 0.1, 0.5]\n",
    "}\n",
    "\n",
    "quick_catboost_params = {\n",
    "    'iterations': [100, 200, 500],\n",
    "    'depth': [4, 6, 8],\n",
    "    'learning_rate': [0.05, 0.1, 0.15],\n",
    "    'l2_leaf_reg': [1, 3, 5]\n",
    "}\n",
    "\n",
    "print(\"\\n⚡ QUICK SEARCH GRIDS (Recommended for initial tuning)\")\n",
    "print(\"=\"*55)\n",
    "print(\"Use these reduced grids with RandomizedSearchCV for faster results:\")\n",
    "print(f\"• Quick Decision Tree: {np.prod([len(v) for v in quick_decision_tree_params.values()]):,} combinations\")\n",
    "print(f\"• Quick Random Forest: {np.prod([len(v) for v in quick_random_forest_params.values()]):,} combinations\")\n",
    "print(f\"• Quick LightGBM: {np.prod([len(v) for v in quick_lightgbm_params.values()]):,} combinations\")\n",
    "print(f\"• Quick XGBoost: {np.prod([len(v) for v in quick_xgboost_params.values()]):,} combinations\")\n",
    "print(f\"• Quick CatBoost: {np.prod([len(v) for v in quick_catboost_params.values()]):,} combinations\")\n",
    "\n",
    "# EXAMPLE IMPLEMENTATION WITH RANDOMIZEDSEARCHCV\n",
    "def run_hyperparameter_tuning(model, param_grid, model_name, X_train, y_train, n_iter=50):\n",
    "    \"\"\"\n",
    "    Run hyperparameter tuning using RandomizedSearchCV\n",
    "    \"\"\"\n",
    "    print(f\"\\n🔍 Tuning {model_name}...\")\n",
    "\n",
    "    # Set up cross-validation\n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    # Create RandomizedSearchCV\n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=model,\n",
    "        param_distributions=param_grid,\n",
    "        n_iter=n_iter,  # Number of parameter combinations to try\n",
    "        cv=cv,\n",
    "        scoring='r2',  # or 'neg_mean_squared_error'\n",
    "        n_jobs=-1,     # Use all CPU cores\n",
    "        verbose=1,     # Print progress\n",
    "        random_state=42,\n",
    "        refit=True     # Refit on best parameters\n",
    "    )\n",
    "\n",
    "    # Fit the model\n",
    "    start_time = time.time()\n",
    "    random_search.fit(X_train, y_train)\n",
    "    end_time = time.time()\n",
    "\n",
    "    print(f\"⏱️  Tuning completed in {end_time - start_time:.2f} seconds\")\n",
    "    print(f\"🏆 Best Score (R2): {random_search.best_score_:.4f}\")\n",
    "    print(f\"🎯 Best Parameters: {random_search.best_params_}\")\n",
    "\n",
    "    return random_search.best_estimator_, random_search.best_params_\n",
    "\n",
    "# Example usage (uncomment to run):\n",
    "#\n",
    "# # Tune Random Forest\n",
    "# best_rf, best_rf_params = run_hyperparameter_tuning(\n",
    "#     model=RandomForestRegressor(random_state=42),\n",
    "#     param_grid=quick_random_forest_params,\n",
    "#     model_name=\"Random Forest\",\n",
    "#     X_train=X_train,\n",
    "#     y_train=y_train,\n",
    "#     n_iter=50\n",
    "# )\n",
    "#\n",
    "# # Tune Decision Tree\n",
    "# best_dt, best_dt_params = run_hyperparameter_tuning(\n",
    "#     model=DecisionTreeRegressor(random_state=42),\n",
    "#     param_grid=quick_decision_tree_params,\n",
    "#     model_name=\"Decision Tree\",\n",
    "#     X_train=X_train,\n",
    "#     y_train=y_train,\n",
    "#     n_iter=30\n",
    "# )\n",
    "\n",
    "print(\"\\n📝 IMPLEMENTATION NOTES:\")\n",
    "print(\"1. Start with 'quick_' parameter grids for faster results\")\n",
    "print(\"2. Use n_iter=50-100 for RandomizedSearchCV\")\n",
    "print(\"3. Increase n_iter for final tuning\")\n",
    "print(\"4. Use the full parameter grids for competition-level performance\")\n",
    "print(\"5. Consider using early_stopping_rounds for XGBoost/LightGBM/CatBoost\")\n",
    "print(\"6. For regression tasks, use 'r2' or 'neg_mean_squared_error' as scoring\")\n",
    "print(\"7. Use KFold instead of StratifiedKFold for regression problems\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
